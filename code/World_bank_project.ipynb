{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkZdJAxYk1do",
    "outputId": "38f75d5b-a674-4a33-ca3c-fe552eb40a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\caleb jensen\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ou754NIel5e2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "02ZxQClTmJ7Q"
   },
   "outputs": [],
   "source": [
    "from config import GOOGLE_API_KEY\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ongLuycOmUht"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "cKT0czkpnG79"
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "cXCAk8dNnMVh",
    "outputId": "a272ec21-ab28-46d8-ae08-7996d555027f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(make_prompt(\"four\", codes[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "lBEpx9Hdne3h",
    "outputId": "7a63d916-99b9-4ee2-f0d8-a9e8b0de0225"
   },
   "outputs": [],
   "source": [
    "response = model.generate_content(make_prompt(\"four\", codes[8]))\n",
    "r = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "data_io = StringIO(r)\n",
    "    \n",
    "# Create first df to be cleaned and returned \n",
    "df = pd.read_csv(data_io, delimiter=\"|\")\n",
    "    \n",
    "# Drop empty top row \n",
    "df = df.iloc[1:].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version 4 Code</th>\n",
       "      <th>Version 3.1 Code</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0122</td>\n",
       "      <td>0113</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version 4 Code   Version 3.1 Code   Proportion \n",
       "0            0122               0113         1.00 "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = df.columns\n",
    "for name in names: \n",
    "    if \"unnamed\" in name.lower(): \n",
    "        df = df.drop(columns = [name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clean'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = df.columns\n",
    "if len(names) == 3 and len(df) != 0:\n",
    "    df[names[2]] = df[names[2]].astype(str)\n",
    "    props = np.array(df[names[2]])\n",
    "    for i in range(len(props)): \n",
    "        if df[names[2]][i] == \"**1**\":\n",
    "            df[names[2]][i] = \"1.00\"\n",
    "        elif type(df[names[2]][i]) == str:\n",
    "            if 'n/a' in df[names[2]][i].lower() or 'NaN' in df[names[2]][i].lower():\n",
    "                df[names[2]][i] = \"0\"\n",
    "    status = \"clean\"\n",
    "    for i in range(len(props)):\n",
    "        if \",\" in props[i] or \"*\" in props[i]:\n",
    "            status = \"broken\"\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "973p9-Mpg35r"
   },
   "outputs": [],
   "source": [
    "##Function takes the created prompt and returns a dataframe that has proportions showing how each 3 digit cade in ISIC 4 is created in ISIC 3.1\n",
    "\n",
    "def get_proportions(prompt):\n",
    "    from io import StringIO\n",
    "    import csv\n",
    "    import pathlib\n",
    "    import textwrap\n",
    "    import google.generativeai as genai\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ## Need to change this line to get your own API key if possible\n",
    "    from config import GOOGLE_API_KEY\n",
    "    \n",
    "    \n",
    "    #setting the model and API key\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    # Input string prompt to the google model \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Define the data string\n",
    "    data_string = response.text\n",
    "    \n",
    "    # Create a StringIO object to mimic a file-like object\n",
    "    data_io = StringIO(data_string)\n",
    "    \n",
    "    # Create first df to be cleaned and returned \n",
    "    df = pd.read_csv(data_io, delimiter=\"|\")\n",
    "    \n",
    "    # Drop empty top row \n",
    "    df = df.iloc[1:].reset_index(drop = True)\n",
    "    \n",
    "    # Drop empty columns\n",
    "    names = df.columns\n",
    "    for name in names: \n",
    "        if \"unnamed\" in name.lower(): \n",
    "            df = df.drop(columns = [name])\n",
    "    # Making proportion column a float between 0 and 1\n",
    "    names = df.columns\n",
    "    print(names)\n",
    "    names_2 = [\"version_4\", \"version_3.1\", \"Proportion of Jobs\"]\n",
    "    df.columns = names_2\n",
    "    ## this is to ensure that the end of the data set is not a row that says \"Total .... 1.00\" which the prompt often returns\n",
    "    ## This needs to be robust if the column type is string or float/int\n",
    "    \n",
    "    if type(df[\"version_4\"].iloc[-1]) == str:\n",
    "        if \"total\" in df[\"version_4\"].iloc[-1].lower() or df[\"version_4\"].iloc[-1].lower() == '': \n",
    "            df = df.iloc[:-1]\n",
    "    elif df[\"Proportion of Jobs\"].iloc[-1] == \"**1.00**\":\n",
    "        if \n",
    "        df = df.iloc[:-1]\n",
    "    elif type(df[\"version_3.1\"].iloc[-1]) == str:\n",
    "        if \"total\" in df[\"version_3.1\"].iloc[-1].lower():\n",
    "            df = df.iloc[:-1]\n",
    "    else:\n",
    "        if df[\"Proportion of Jobs\"].iloc[-1] == 1 or \"1.00\" in df[\"Proportion of Jobs\"].iloc[-1]:\n",
    "            df = df.iloc[:-1]\n",
    "    \n",
    "     # Making proportion column a float between 0 and 1\n",
    "    df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].str.strip()\n",
    "    df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].str.replace(\"%\", \"\")\n",
    "    df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].astype(float) \n",
    "    if df[\"Proportion of Jobs\"][0] > 1:\n",
    "        df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"]/100 \n",
    "    \n",
    "    # Replace non-numeric characters with an empty string\n",
    "    pattern = r'\\D'  # Matches any non-digit character\n",
    "    df[\"version_4\"] = df[\"version_4\"].str.replace(pattern, '')    \n",
    "    df[\"version_3.1\"] = df[\"version_3.1\"].str.replace(pattern, '')\n",
    "    \n",
    "    ## scale the data frame\n",
    "    df = df.reset_index(drop = True)\n",
    "    if df[\"Proportion of Jobs\"].sum() > 1:\n",
    "        total = df[\"Proportion of Jobs\"].sum()\n",
    "        for i in range(len(df[\"Proportion of Jobs\"])):\n",
    "            df[\"Proportion of Jobs\"][i] = df[\"Proportion of Jobs\"][i]/total\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_one_cleaning(prompt):  \n",
    "    from io import StringIO\n",
    "    import csv\n",
    "    import pathlib\n",
    "    import textwrap\n",
    "    import google.generativeai as genai\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ## Need to change this line to get your own API key if possible\n",
    "    from config import GOOGLE_API_KEY\n",
    "    \n",
    "    \n",
    "    #setting the model and API key\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    # Input string prompt to the google model \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Define the data string\n",
    "    data_string = response.text\n",
    "    \n",
    "    # Create a StringIO object to mimic a file-like object\n",
    "    data_io = StringIO(data_string)\n",
    "    \n",
    "    # Create first df to be cleaned and returned \n",
    "    df = pd.read_csv(data_io, delimiter=\"|\")\n",
    "    \n",
    "    # Drop empty top row \n",
    "    df = df.iloc[1:].reset_index(drop = True)\n",
    "    \n",
    "    # Drop empty columns\n",
    "    names = df.columns\n",
    "    for name in names: \n",
    "        if \"unnamed\" in name.lower(): \n",
    "            df = df.drop(columns = [name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_two_cleaning(prompt):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from collections import Counter\n",
    "    status = \"broken\"\n",
    "    while status == \"broken\":\n",
    "        df = step_one_cleaning(prompt)\n",
    "        names = df.columns\n",
    "        if len(names) == 3 and len(df) != 0:\n",
    "            count = Counter(df[names[2]][0])\n",
    "            if count[\".\"] == 1:\n",
    "                df[names[2]] = df[names[2]].astype(str)\n",
    "                props = np.array(df[names[2]])\n",
    "                for i in range(len(props)): \n",
    "                    if df[names[2]][i] == \"**1**\":\n",
    "                        df[names[2]][i] = \"1.00\"\n",
    "                    elif type(df[names[2]][i]) == str:\n",
    "                        if 'n/a' in df[names[2]][i].lower() or 'NaN' in df[names[2]][i].lower():\n",
    "                            df[names[2]][i] = \"0\"\n",
    "                status = \"clean\"\n",
    "                for i in range(len(props)):\n",
    "                    if \",\" in props[i] or \"*\" in props[i]:\n",
    "                        status = \"broken\"\n",
    "    # Making proportion column a float between 0 and 1\n",
    "    names = df.columns\n",
    "    names_2 = [\"version_4\", \"version_3.1\", \"Proportion of Jobs\"]\n",
    "    df.columns = names_2\n",
    "    ## this is to ensure that the end of the data set is not a row that says \"Total .... 1.00\" which the prompt often returns\n",
    "    ## This needs to be robust if the column type is string or float/int\n",
    "    \n",
    "    if type(df[\"version_4\"].iloc[-1]) == str:\n",
    "        if \"total\" in df[\"version_4\"].iloc[-1].lower() or df[\"version_4\"].iloc[-1].lower() == '': \n",
    "            df = df.iloc[:-1]\n",
    "    elif type(df[\"version_3.1\"].iloc[-1]) == str:\n",
    "        if \"total\" in df[\"version_3.1\"].iloc[-1].lower():\n",
    "            df = df.iloc[:-1]\n",
    "    \n",
    "    # Replace non-numeric characters with an empty string\n",
    "    pattern = r'\\D'  # Matches any non-digit character\n",
    "    if type(df[\"version_4\"]) == str:\n",
    "        df[\"version_4\"] = df[\"version_4\"].str.replace(pattern, '') \n",
    "    if type(df[\"version_3.1\"]) == str:\n",
    "        df[\"version_3.1\"] = df[\"version_3.1\"].str.replace(pattern, '')\n",
    "    \n",
    "    # Making proportion column a float between 0 and 1\n",
    "    if type(df[\"Proportion of Jobs\"][0]) == str:\n",
    "        df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].str.strip()\n",
    "        df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].str.replace(\"%\", \"\")\n",
    "        df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"].astype(float) \n",
    "    if df[\"Proportion of Jobs\"][0] > 1:\n",
    "        df[\"Proportion of Jobs\"] = df[\"Proportion of Jobs\"]/100 \n",
    "    \n",
    "    ## scale the data frame\n",
    "    df = df.reset_index(drop = True)\n",
    "    if df[\"Proportion of Jobs\"].sum() > 1:\n",
    "        total = df[\"Proportion of Jobs\"].sum()\n",
    "        for i in range(len(df[\"Proportion of Jobs\"])):\n",
    "            df[\"Proportion of Jobs\"][i] = df[\"Proportion of Jobs\"][i]/total\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_proportions(prompt):\n",
    "    from io import StringIO\n",
    "    import csv\n",
    "    import pathlib\n",
    "    import textwrap\n",
    "    import google.generativeai as genai\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ## Need to change this line to get your own API key if possible\n",
    "    from config import GOOGLE_API_KEY\n",
    "    #setting the model and API key\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    # Input string prompt to the google model \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Define the data string\n",
    "    data_string = response.text\n",
    "    \n",
    "    # Create a StringIO object to mimic a file-like object\n",
    "    data_io = StringIO(data_string)\n",
    "    \n",
    "    # Create first df to be cleaned and returned \n",
    "    df = pd.read_csv(data_io, delimiter=\"|\")\n",
    "    \n",
    "    # Drop empty top row \n",
    "    df = df.iloc[1:].reset_index(drop = True)\n",
    "    \n",
    "    # Drop empty columns\n",
    "    names = df.columns\n",
    "    names = df.columns\n",
    "    names_2 = []\n",
    "    for name in names: \n",
    "        if \"unnamed\" not in name.lower(): \n",
    "            names_2.append(name)\n",
    "    return names_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a usable prompt \n",
    "## Start by importing the correspondence table and .txt files with with codes and descriptions\n",
    "corr_table = pd.read_csv(\"ISIC4_ISIC31.csv\", dtype={\"ISIC4code\": str, \"partialISIC4\": str, \"ISIC31code\": str, \"partialISIC31\": str})\n",
    "corr_table = corr_table.fillna(\"\")\n",
    "ISIC_4 = pd.read_csv(\"isic4.txt\", dtype={'num': str}, delimiter = \"|\")\n",
    "ISIC_31 = pd.read_csv(\"isic31.txt\", dtype={'num': str}, delimiter = \"|\")\n",
    "col_names = [\"code\", \"description\"]\n",
    "ISIC_4.columns = col_names\n",
    "ISIC_31.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ISIC_31.columns \n",
    "data = {names[0]: [\"6712\"], names[1]: [\"Security dealing activities\"]}\n",
    "df_small = pd.DataFrame(data)\n",
    "ISIC_31 = pd.concat([ISIC_31, df_small])\n",
    "ISIC_31 = ISIC_31.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(codes)):\n",
    "    print(i)\n",
    "    make_prompt(\"four\", codes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>6712</td>\n",
       "      <td>Security dealing activities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code                  description\n",
       "517  6712  Security dealing activities"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISIC_3_4digit[ISIC_3_4digit['code'] == \"6712\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISIC_31.to_excel(\"ISIC_31.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data and making dfs for each code length \n",
    "code_length_4 = ISIC_4['code'].str.len()\n",
    "code_length_31 = ISIC_31['code'].str.len()\n",
    "\n",
    "# Filter DataFrames based on code length\n",
    "ISIC_4_2digit = ISIC_4[code_length_4 == 2]\n",
    "ISIC_4_3digit = ISIC_4[code_length_4 == 3]\n",
    "ISIC_4_4digit = ISIC_4[code_length_4 == 4]\n",
    "\n",
    "ISIC_3_2digit = ISIC_31[code_length_31 == 2]\n",
    "ISIC_3_3digit = ISIC_31[code_length_31 == 3]\n",
    "ISIC_3_4digit = ISIC_31[code_length_31 == 4]\n",
    "\n",
    "# Making 3 digit and 2 digit 4.0 codes columns in the correspondence table \n",
    "corr_table['ISIC_4_3d'] = corr_table['ISIC4code'].str[:3]\n",
    "corr_table['ISIC_4_2d'] = corr_table['ISIC4code'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(digits, four_code):\n",
    "    num_codes = corr_table[\"ISIC4code\"].value_counts()\n",
    "    prompt = \"A \" + digits + \" digit code \" + four_code + \" which is (\" + str(ISIC_4_4digit[ISIC_4_4digit[\"code\"] == four_code][\"description\"].iloc[0]) + \") in ISIC version 4 is comprised of \" + str(num_codes[four_code]) + \" four digit codes in ISICs version 3.1, \"\n",
    "    codes_31 = corr_table[corr_table[\"ISIC4code\"] == four_code]\n",
    "    ## Code to handle when there are multiple instances of a code and possibly multiple \"details\" for that code in the correspondence table\n",
    "    for code in codes_31[\"ISIC31code\"].unique(): \n",
    "        ## start by just adding the code and its standard description from the ISIC code data frame\n",
    "        prompt = prompt + code + \" which is (\" + ISIC_3_4digit[ISIC_3_4digit['code'] == code]['description'].iloc[0] + \"), \"\n",
    "        ## now test if the code is unique, that is, it only appears once within the 3 digit code we are considering from version 4\n",
    "        if codes_31['ISIC31code'].eq(code).sum() == 1:\n",
    "            ## If it is unique, we test if the detail column of the correspondence table is empty, if it is not we add that extra detail to the prompt\n",
    "            if codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[0] != \"\":\n",
    "                prompt = prompt + \" and includes (\" + codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[0] + \") \"\n",
    "        elif codes_31['ISIC31code'].eq(code).sum() > 1:\n",
    "            ## we now test if the code is not unique, if this is the case our code is more complicated, start by making an index list that will track appearances of this code\n",
    "            ind = []\n",
    "            ## Now we will loop through the instances of the code and add the index of each instance if the detail section is not empty, we are collecting all the different details to include \n",
    "            for i in range(codes_31['ISIC31code'].eq(code).sum()):\n",
    "                if codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[i] != \"\":\n",
    "                    ind.append(i)\n",
    "            ## If the code is repeated but never with a detail the prompt remains unchanged\n",
    "            if len(ind) == 0:\n",
    "                prompt = prompt\n",
    "            ## If the code is repeated but only with 1 detail, just include that single detail\n",
    "            elif len(ind) == 1:\n",
    "                prompt = prompt + \"and includes (\" + codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[ind[0]] + \", \"\n",
    "            ## If the code is repeated with multiple details, start with the first detail and drop the first item in the list so it is not repeated, then loop through the list adding all the details\n",
    "            else: \n",
    "                prompt = prompt + \" and includes (\" + codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[ind[0]]\n",
    "                ind = ind[1:]\n",
    "                for k in ind:\n",
    "                    prompt = prompt + \", and (\" + codes_31[codes_31[\"ISIC31code\"] == code][\"Detail\"].iloc[k] + \")\"\n",
    "    if num_codes[four_code] > 10:\n",
    "        prompt = prompt + \" What is your best estimate of the proportion of jobs now coded in \" + four_code + \" that were in each of the previous codes in version 3.1? The proportions can be less than .05 and many probably are less .05. Can you make sure these proportions all sum to 1? Can you give me your best guesses in a table with 3 columns, first the three digit code, \" + four_code + \" then the four didgit codes, then the proportions?\"\n",
    "    else: \n",
    "        prompt = prompt + \" What is your best estimate of the proportion of jobs now coded in \" + four_code + \" that were in each of the previous codes in version 3.1? If there is only 1 version 3.1 code, it is automatically 1. Can you give me your best guesses in a table with 3 columns, first the version 4 code, \" + four_code + \" then the version 3.1 codes, then the proportions?\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    },
    {
     "ename": "DeadlineExceeded",
     "evalue": "504 Deadline Exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDeadlineExceeded\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m four_code \u001b[38;5;129;01min\u001b[39;00m codes:\n\u001b[0;32m      5\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m make_prompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m\"\u001b[39m, four_code)\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m step_two_cleaning(prompt)\n\u001b[0;32m      7\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mstep_two_cleaning\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      5\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroken\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroken\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m step_one_cleaning(prompt)\n\u001b[0;32m      8\u001b[0m     names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mstep_one_cleaning\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Input string prompt to the google model \u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Define the data string\u001b[39;00m\n\u001b[0;32m     22\u001b[0m data_string \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\generativeai\\generative_models.py:232\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, request_options)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    233\u001b[0m         request,\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:566\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    561\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m    562\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    567\u001b[0m     request,\n\u001b[0;32m    568\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    569\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    570\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDeadlineExceeded\u001b[0m: 504 Deadline Exceeded"
     ]
    }
   ],
   "source": [
    "codes = np.array(ISIC_4_4digit[\"code\"])\n",
    "df_big = pd.DataFrame({'version_4': [], 'version_3.1': [], \"Proportion of Jobs\": []})\n",
    "i = 0\n",
    "for four_code in codes:\n",
    "    prompt = make_prompt(\"four\", four_code)\n",
    "    df = step_two_cleaning(prompt)\n",
    "    i += 1\n",
    "    print(i)\n",
    "    df_big = pd.concat([df_big, df])\n",
    "    df_big = df_big[df_big.notna().all(axis=1)]\n",
    "    df_big = df_big.reset_index(drop = True)\n",
    "df_big.to_excel(\"correspondence_table.xlsx\", index=True)\n",
    "print(df_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.to_excel(\"correspondence_table.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#my_string = \"Hello, world!\"\n",
    "#char_counts = Counter(my_string)\n",
    "char_counts[\"l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
